# Default Spring Boot metadata for the LLM module
spring.application.name=llm
server.port=17005
server.servlet.context-path=/vision-mind-llm

# Default LLM service endpoints shared across applications
#ollama.base-url=http://127.0.0.1:11434
#ollama.chat.options.model=gemma3:4b

# OpenAI settings are optional; comment out if unused
openai.base-url=https://ark.cn-beijing.volces.com/api/v3/chat/completions
openai.api-key=7bbb5cb7-8524-4646-854c-5ea095f3116d
openai.chat.options.model=ep-20250327212217-f57wv

# HTTP timeout (milliseconds) applied to outbound LLM calls
llm.http-timeout-ms=1000000
