spring.application.name=llm
server.port=17004

server.servlet.context-path=/vision-mind-llm
# Configure either Ollama or OpenAI endpoints; OpenAI takes precedence when both are set
ollama.base-url=http://127.0.0.1:11434
ollama.chat.options.model=gemma3:1b

openai.base-url=
openai.api-key=
openai.chat.options.model=
#openai.base-url=ark.cn-beijing.volces.com/api/v3/chat/completions
#openai.api-key=YOUR_API_KEY
#openai.chat.options.model=ep-20250327212217-f57wv
