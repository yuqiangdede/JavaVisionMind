spring.application.name=tbir-cn
server.port=17009
server.address=0.0.0.0
server.servlet.context-path=/vision-mind-tbir-cn

spring.servlet.multipart.enabled=true
spring.servlet.multipart.max-file-size=10MB
spring.servlet.multipart.max-request-size=10MB

# Root directory (relative to this process) for auxiliary component assets
component.path=..

# MetaCLIP2 model resources used for feature extraction
img.onnx=./resource/tbir/model-cn/metaclip2-mt5-m16-img-512.onnx
text.onnx=./resource/tbir/model-cn/metaclip2-mt5-m16-text-512.onnx
# Tokenizer files directory (HuggingFace tokenizers JSON/BPE assets)
clip.tokenizer=./resource/tbir/clip-tokenizer-cn

# Vision encoder (CLIP / MetaCLIP2) IO settings for ONNX exports
vision.image.size=224
vision.image.input=pixel_values
vision.image.mean=0.48145466,0.4578275,0.40821073
vision.image.std=0.26862954,0.26130258,0.27577711
vision.text.input-ids=input_ids
vision.text.attention-mask=attention_mask

# Enable detection-driven vectorization; specify comma-separated detector types (e.g. yolo,sam)
open.detect=true
detect.types=sam
# Filter crops by bounding box size in pixels: min,max
filter.box.size=50,300

# Enabled image augmentation types for indexing; comma-separated operations such as:
# - original: store the unmodified image
# - flipH: include a horizontally flipped version
# - rotate15 / rotate-15: include 15-degree clockwise / counter-clockwise rotations
# - blur: apply a mild Gaussian blur
# - bright: increase overall brightness
# - contrast: enhance contrast levels
augment.types=original,flipH,rotate15,rotate-15,blur,bright,contrast

# Number of expanded search keywords
key.expand.num=5

# Vector store selection for semantic indexing
vector.store.mode=memory
# Storage backend: lucene, memory, elasticsearch
# - When set to `lucene`, configure the `lucene.path` directory above
lucene.path=/data/tbirIndexCn
# - When set to `elasticsearch`, supply the `es.*` parameters below
es.uris=http://127.0.0.1:9200
es.username=
es.password=
es.api-key=
es.index.tbir=vision_mind_tbir_cn
