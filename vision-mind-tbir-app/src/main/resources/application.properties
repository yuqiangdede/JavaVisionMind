spring.application.name=tbir
server.port=17003
server.address=0.0.0.0
server.servlet.context-path=/vision-mind-tbir

# Enable multipart/form-data uploads
spring.servlet.multipart.enabled=true
# Maximum allowed size for a single uploaded file
spring.servlet.multipart.max-file-size=10MB
# Maximum allowed size for the entire multipart request
spring.servlet.multipart.max-request-size=10MB

# Root directory (relative to this process) for auxiliary component assets
component.path=..

# Enable GPU acceleration where available (experimental and currently unsupported)
use.gpu=false

# Platform-specific paths to the OpenCV native libraries
opencv.dll.path=/lib/opencv/opencv_java490.dll
opencv.so.path=/lib/opencv/libopencv_java4100.so

# CLIP model resources used for feature extraction
img.onnx=/tbir/model/clip-vit-b32-img.onnx
text.onnx=/tbir/model/clip-vit-b32-text.onnx
clip.tokenizer=/tbir/clip-tokenizer


# Enable detection-driven vectorization; specify comma-separated detector types (e.g. yolo,sam)
open.detect=true
detect.types=yolo,sam
# Filter crops by bounding box size in pixels: min,max
filter.box.size=50,300

# Enabled image augmentation types for indexing; comma-separated operations such as:
# - original: store the unmodified image
# - flipH: include a horizontally flipped version
# - rotate15 / rotate-15: include 15-degree clockwise / counter-clockwise rotations
# - blur: apply a mild Gaussian blur
# - bright: increase overall brightness
# - contrast: enhance contrast levels
augment.types=original,flipH

# Number of expanded search keywords
key.expand.num=5

# Confidence threshold used when callers omit a value
yolo.conf.Threshold=0.3
yolo.pose.conf.Threshold=0.3
# Default YOLO classes when the request omits types
yolo.types=0,1,2,3,4,5,6,7,8
# Minimum overlap ratio between detection box and allowed area
detect.ratio=0.5
# Maximum overlap ratio allowed with blocked regions
block.ratio=0.5
# Non-maximum suppression threshold
yolo.nms.Threshold=0.3
# SAM detection threshold
sam.nms.Threshold=0.5

# YOLO-derived ONNX model locations for various tasks
yolo.onnx.path=/yolo/model/yolo.onnx
yolo.face.onnx.path=/yolo/model/yolo-face.onnx
yolo.pose.onnx.path=/yolo/model/yolo-pose.onnx
yolo.sam.onnx.path=/yolo/model/FastSAM-s.onnx

# Frame interval (in frames) for video analysis
frame.interval=5

# Configure either Ollama or OpenAI style endpoints. When both are provided, OpenAI takes precedence.
ollama.base-url=http://127.0.0.1:11434
ollama.chat.options.model=gemma3:1b

openai.base-url=
openai.api-key=
openai.chat.options.model=
#openai.base-url=api.openai.com
#openai.api-key=xxxxxxxxxxxxxxx
#openai.chat.options.model=gpt-4o-mini

# Vector store selection for semantic indexing
vector.store.mode=memory
# Storage backend: lucene, memory, elasticsearch
# - When set to `lucene`, configure the `lucene.path` directory above
lucene.path=/data/tbirIndex
# - When set to `elasticsearch`, supply the `es.*` parameters below
es.uris=http://127.0.0.1:9200
es.username=
es.password=
es.api-key=
es.index.tbir=vision_mind_tbir
